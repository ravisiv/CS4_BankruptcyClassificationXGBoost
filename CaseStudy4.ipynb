{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "789e574a",
   "metadata": {},
   "source": [
    "### Case Study 4 : Financial Delinquency\n",
    "\n",
    "Submitted by:\n",
    "\n",
    "- Ravi Sivaraman\n",
    "- Balaji Avvaru\n",
    "- Apurv Mittal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b98e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve, accuracy_score, confusion_matrix, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize, StandardScaler\n",
    "from sklearn import metrics as mt\n",
    "import getpass\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14ba29b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_user = getpass.getuser()\n",
    "\n",
    "if current_user == 'balaj':\n",
    "    data_path = \"/Users/balaj/OneDrive/Desktop/Docs/Docs 1/SMU/MSDS 7333/Case Study 4/Data/\"\n",
    "elif current_user == 'ravis':\n",
    "    data_path = \"/Users/ravis/Library/CloudStorage/OneDrive-SouthernMethodistUniversity/Case Study 4/Data/\"\n",
    "elif current_user == \"apurv\":\n",
    "    data_path = \"/Users/apurv/Library/CloudStorage/OneDrive-SouthernMethodistUniversity/SMU/7333 - QTW/Case Study 4/Data/\"\n",
    "\n",
    "# get all data files\n",
    "data_files = [f for f in os.listdir(data_path) if (not f.startswith('.')) and os.path.isfile(join(data_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03fb9d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2year.arff', '3year.arff', '5year.arff', '4year.arff', '1year.arff']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f66b25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for f in data_files:\n",
    "    data_temp = arff.loadarff(data_path+f)\n",
    "    temp_df = pd.DataFrame(data_temp[0])\n",
    "    df = df.append(temp_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb14852c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43405, 65)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "604eaed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr1</th>\n",
       "      <th>Attr2</th>\n",
       "      <th>Attr3</th>\n",
       "      <th>Attr4</th>\n",
       "      <th>Attr5</th>\n",
       "      <th>Attr6</th>\n",
       "      <th>Attr7</th>\n",
       "      <th>Attr8</th>\n",
       "      <th>Attr9</th>\n",
       "      <th>Attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attr56</th>\n",
       "      <th>Attr57</th>\n",
       "      <th>Attr58</th>\n",
       "      <th>Attr59</th>\n",
       "      <th>Attr60</th>\n",
       "      <th>Attr61</th>\n",
       "      <th>Attr62</th>\n",
       "      <th>Attr63</th>\n",
       "      <th>Attr64</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.202350</td>\n",
       "      <td>0.46500</td>\n",
       "      <td>0.240380</td>\n",
       "      <td>1.5171</td>\n",
       "      <td>-14.547</td>\n",
       "      <td>0.510690</td>\n",
       "      <td>0.25366</td>\n",
       "      <td>0.91816</td>\n",
       "      <td>1.15190</td>\n",
       "      <td>0.42695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13184</td>\n",
       "      <td>0.473950</td>\n",
       "      <td>0.86816</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>8.5487</td>\n",
       "      <td>5.16550</td>\n",
       "      <td>107.740</td>\n",
       "      <td>3.38790</td>\n",
       "      <td>5.3440</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030073</td>\n",
       "      <td>0.59563</td>\n",
       "      <td>0.186680</td>\n",
       "      <td>1.3382</td>\n",
       "      <td>-37.859</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>0.04167</td>\n",
       "      <td>0.67890</td>\n",
       "      <td>0.32356</td>\n",
       "      <td>0.40437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12146</td>\n",
       "      <td>0.074369</td>\n",
       "      <td>0.87235</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.5264</td>\n",
       "      <td>0.63305</td>\n",
       "      <td>622.660</td>\n",
       "      <td>0.58619</td>\n",
       "      <td>1.2381</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.257860</td>\n",
       "      <td>0.29949</td>\n",
       "      <td>0.665190</td>\n",
       "      <td>3.2211</td>\n",
       "      <td>71.799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.31877</td>\n",
       "      <td>2.33200</td>\n",
       "      <td>1.67620</td>\n",
       "      <td>0.69841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16499</td>\n",
       "      <td>0.369210</td>\n",
       "      <td>0.81614</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.3325</td>\n",
       "      <td>3.19850</td>\n",
       "      <td>65.215</td>\n",
       "      <td>5.59690</td>\n",
       "      <td>47.4660</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.227160</td>\n",
       "      <td>0.67850</td>\n",
       "      <td>0.042784</td>\n",
       "      <td>1.0828</td>\n",
       "      <td>-88.212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.28505</td>\n",
       "      <td>0.47384</td>\n",
       "      <td>1.32410</td>\n",
       "      <td>0.32150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29358</td>\n",
       "      <td>0.706570</td>\n",
       "      <td>0.78617</td>\n",
       "      <td>0.48456</td>\n",
       "      <td>5.2309</td>\n",
       "      <td>5.06750</td>\n",
       "      <td>142.460</td>\n",
       "      <td>2.56210</td>\n",
       "      <td>3.0066</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085443</td>\n",
       "      <td>0.38039</td>\n",
       "      <td>0.359230</td>\n",
       "      <td>1.9444</td>\n",
       "      <td>21.731</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.10823</td>\n",
       "      <td>1.37140</td>\n",
       "      <td>1.11260</td>\n",
       "      <td>0.52167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10124</td>\n",
       "      <td>0.163790</td>\n",
       "      <td>0.89876</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.7035</td>\n",
       "      <td>4.00200</td>\n",
       "      <td>89.058</td>\n",
       "      <td>4.09840</td>\n",
       "      <td>5.9874</td>\n",
       "      <td>b'0'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Attr1    Attr2     Attr3   Attr4   Attr5     Attr6    Attr7    Attr8  \\\n",
       "0  0.202350  0.46500  0.240380  1.5171 -14.547  0.510690  0.25366  0.91816   \n",
       "1  0.030073  0.59563  0.186680  1.3382 -37.859 -0.000319  0.04167  0.67890   \n",
       "2  0.257860  0.29949  0.665190  3.2211  71.799  0.000000  0.31877  2.33200   \n",
       "3  0.227160  0.67850  0.042784  1.0828 -88.212  0.000000  0.28505  0.47384   \n",
       "4  0.085443  0.38039  0.359230  1.9444  21.731  0.187900  0.10823  1.37140   \n",
       "\n",
       "     Attr9   Attr10  ...   Attr56    Attr57   Attr58   Attr59  Attr60  \\\n",
       "0  1.15190  0.42695  ...  0.13184  0.473950  0.86816  0.00024  8.5487   \n",
       "1  0.32356  0.40437  ...  0.12146  0.074369  0.87235  0.00000  1.5264   \n",
       "2  1.67620  0.69841  ...  0.16499  0.369210  0.81614  0.00000  4.3325   \n",
       "3  1.32410  0.32150  ...  0.29358  0.706570  0.78617  0.48456  5.2309   \n",
       "4  1.11260  0.52167  ...  0.10124  0.163790  0.89876  0.00000  5.7035   \n",
       "\n",
       "    Attr61   Attr62   Attr63   Attr64  class  \n",
       "0  5.16550  107.740  3.38790   5.3440   b'0'  \n",
       "1  0.63305  622.660  0.58619   1.2381   b'0'  \n",
       "2  3.19850   65.215  5.59690  47.4660   b'0'  \n",
       "3  5.06750  142.460  2.56210   3.0066   b'0'  \n",
       "4  4.00200   89.058  4.09840   5.9874   b'0'  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67d2eec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43405 entries, 0 to 43404\n",
      "Data columns (total 65 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Attr1   43397 non-null  float64\n",
      " 1   Attr2   43397 non-null  float64\n",
      " 2   Attr3   43397 non-null  float64\n",
      " 3   Attr4   43271 non-null  float64\n",
      " 4   Attr5   43316 non-null  float64\n",
      " 5   Attr6   43397 non-null  float64\n",
      " 6   Attr7   43397 non-null  float64\n",
      " 7   Attr8   43311 non-null  float64\n",
      " 8   Attr9   43396 non-null  float64\n",
      " 9   Attr10  43397 non-null  float64\n",
      " 10  Attr11  43361 non-null  float64\n",
      " 11  Attr12  43271 non-null  float64\n",
      " 12  Attr13  43278 non-null  float64\n",
      " 13  Attr14  43397 non-null  float64\n",
      " 14  Attr15  43369 non-null  float64\n",
      " 15  Attr16  43310 non-null  float64\n",
      " 16  Attr17  43311 non-null  float64\n",
      " 17  Attr18  43397 non-null  float64\n",
      " 18  Attr19  43277 non-null  float64\n",
      " 19  Attr20  43278 non-null  float64\n",
      " 20  Attr21  37551 non-null  float64\n",
      " 21  Attr22  43397 non-null  float64\n",
      " 22  Attr23  43278 non-null  float64\n",
      " 23  Attr24  42483 non-null  float64\n",
      " 24  Attr25  43397 non-null  float64\n",
      " 25  Attr26  43310 non-null  float64\n",
      " 26  Attr27  40641 non-null  float64\n",
      " 27  Attr28  42593 non-null  float64\n",
      " 28  Attr29  43397 non-null  float64\n",
      " 29  Attr30  43278 non-null  float64\n",
      " 30  Attr31  43278 non-null  float64\n",
      " 31  Attr32  43037 non-null  float64\n",
      " 32  Attr33  43271 non-null  float64\n",
      " 33  Attr34  43311 non-null  float64\n",
      " 34  Attr35  43397 non-null  float64\n",
      " 35  Attr36  43397 non-null  float64\n",
      " 36  Attr37  24421 non-null  float64\n",
      " 37  Attr38  43397 non-null  float64\n",
      " 38  Attr39  43278 non-null  float64\n",
      " 39  Attr40  43271 non-null  float64\n",
      " 40  Attr41  42651 non-null  float64\n",
      " 41  Attr42  43278 non-null  float64\n",
      " 42  Attr43  43278 non-null  float64\n",
      " 43  Attr44  43278 non-null  float64\n",
      " 44  Attr45  41258 non-null  float64\n",
      " 45  Attr46  43270 non-null  float64\n",
      " 46  Attr47  43108 non-null  float64\n",
      " 47  Attr48  43396 non-null  float64\n",
      " 48  Attr49  43278 non-null  float64\n",
      " 49  Attr50  43311 non-null  float64\n",
      " 50  Attr51  43397 non-null  float64\n",
      " 51  Attr52  43104 non-null  float64\n",
      " 52  Attr53  42593 non-null  float64\n",
      " 53  Attr54  42593 non-null  float64\n",
      " 54  Attr55  43404 non-null  float64\n",
      " 55  Attr56  43278 non-null  float64\n",
      " 56  Attr57  43398 non-null  float64\n",
      " 57  Attr58  43321 non-null  float64\n",
      " 58  Attr59  43398 non-null  float64\n",
      " 59  Attr60  41253 non-null  float64\n",
      " 60  Attr61  43303 non-null  float64\n",
      " 61  Attr62  43278 non-null  float64\n",
      " 62  Attr63  43271 non-null  float64\n",
      " 63  Attr64  42593 non-null  float64\n",
      " 64  class   43405 non-null  object \n",
      "dtypes: float64(64), object(1)\n",
      "memory usage: 21.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d8924",
   "metadata": {},
   "source": [
    "##### Missing value analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d35a574c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41322"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate null values in the csv file\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4983d700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attr37    18984\n",
      "Attr21     5854\n",
      "Attr27     2764\n",
      "Attr60     2152\n",
      "Attr45     2147\n",
      "Attr24      922\n",
      "Attr64      812\n",
      "Attr53      812\n",
      "Attr28      812\n",
      "Attr54      812\n",
      "Attr41      754\n",
      "Attr32      368\n",
      "Attr52      301\n",
      "Attr47      297\n",
      "Attr46      135\n",
      "Attr33      134\n",
      "Attr4       134\n",
      "Attr40      134\n",
      "Attr12      134\n",
      "Attr63      134\n",
      "Attr19      128\n",
      "Attr30      127\n",
      "Attr44      127\n",
      "Attr43      127\n",
      "Attr42      127\n",
      "Attr39      127\n",
      "Attr49      127\n",
      "Attr62      127\n",
      "Attr31      127\n",
      "Attr23      127\n",
      "Attr56      127\n",
      "Attr13      127\n",
      "Attr20      127\n",
      "Attr61      102\n",
      "Attr26       95\n",
      "Attr16       95\n",
      "Attr8        94\n",
      "Attr34       94\n",
      "Attr17       94\n",
      "Attr50       94\n",
      "Attr5        89\n",
      "Attr58       84\n",
      "Attr11       44\n",
      "Attr15       36\n",
      "Attr9         9\n",
      "Attr48        9\n",
      "Attr51        8\n",
      "Attr1         8\n",
      "Attr38        8\n",
      "Attr7         8\n",
      "Attr35        8\n",
      "Attr2         8\n",
      "Attr29        8\n",
      "Attr25        8\n",
      "Attr3         8\n",
      "Attr22        8\n",
      "Attr36        8\n",
      "Attr18        8\n",
      "Attr6         8\n",
      "Attr14        8\n",
      "Attr10        8\n",
      "Attr57        7\n",
      "Attr59        7\n",
      "Attr55        1\n",
      "class         0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Columns with null values\n",
      "************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Attr1', 'Attr2', 'Attr3', 'Attr4', 'Attr5', 'Attr6', 'Attr7', 'Attr8',\n",
       "       'Attr9', 'Attr10', 'Attr11', 'Attr12', 'Attr13', 'Attr14', 'Attr15',\n",
       "       'Attr16', 'Attr17', 'Attr18', 'Attr19', 'Attr20', 'Attr21', 'Attr22',\n",
       "       'Attr23', 'Attr24', 'Attr25', 'Attr26', 'Attr27', 'Attr28', 'Attr29',\n",
       "       'Attr30', 'Attr31', 'Attr32', 'Attr33', 'Attr34', 'Attr35', 'Attr36',\n",
       "       'Attr37', 'Attr38', 'Attr39', 'Attr40', 'Attr41', 'Attr42', 'Attr43',\n",
       "       'Attr44', 'Attr45', 'Attr46', 'Attr47', 'Attr48', 'Attr49', 'Attr50',\n",
       "       'Attr51', 'Attr52', 'Attr53', 'Attr54', 'Attr55', 'Attr56', 'Attr57',\n",
       "       'Attr58', 'Attr59', 'Attr60', 'Attr61', 'Attr62', 'Attr63', 'Attr64'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "# Validate null values in the csv file\n",
    "print((df.isnull().sum()).sort_values(ascending=False))\n",
    "# print columns with null values\n",
    "missing_data_columns = df.columns[df.isnull().any()]\n",
    "print(\"\\n\\nColumns with null values\")\n",
    "print(\"************************\")\n",
    "missing_data_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9f02347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attr37    43.736897\n",
       "Attr21    13.486925\n",
       "Attr27     6.367930\n",
       "Attr60     4.957954\n",
       "Attr45     4.946435\n",
       "Attr24     2.124179\n",
       "Attr28     1.870752\n",
       "Attr64     1.870752\n",
       "Attr53     1.870752\n",
       "Attr54     1.870752\n",
       "Attr41     1.737127\n",
       "Attr32     0.847829\n",
       "Attr52     0.693468\n",
       "Attr47     0.684253\n",
       "Attr46     0.311024\n",
       "Attr40     0.308720\n",
       "Attr63     0.308720\n",
       "Attr33     0.308720\n",
       "Attr4      0.308720\n",
       "Attr12     0.308720\n",
       "Attr19     0.294897\n",
       "Attr31     0.292593\n",
       "Attr62     0.292593\n",
       "Attr56     0.292593\n",
       "Attr49     0.292593\n",
       "Attr44     0.292593\n",
       "Attr43     0.292593\n",
       "Attr20     0.292593\n",
       "Attr39     0.292593\n",
       "Attr13     0.292593\n",
       "Attr42     0.292593\n",
       "Attr30     0.292593\n",
       "Attr23     0.292593\n",
       "Attr61     0.234996\n",
       "Attr16     0.218869\n",
       "Attr26     0.218869\n",
       "Attr34     0.216565\n",
       "Attr50     0.216565\n",
       "Attr17     0.216565\n",
       "Attr8      0.216565\n",
       "Attr5      0.205046\n",
       "Attr58     0.193526\n",
       "Attr11     0.101371\n",
       "Attr15     0.082940\n",
       "Attr9      0.020735\n",
       "Attr48     0.020735\n",
       "Attr7      0.018431\n",
       "Attr22     0.018431\n",
       "Attr18     0.018431\n",
       "Attr3      0.018431\n",
       "Attr6      0.018431\n",
       "Attr14     0.018431\n",
       "Attr51     0.018431\n",
       "Attr2      0.018431\n",
       "Attr10     0.018431\n",
       "Attr25     0.018431\n",
       "Attr29     0.018431\n",
       "Attr38     0.018431\n",
       "Attr36     0.018431\n",
       "Attr35     0.018431\n",
       "Attr1      0.018431\n",
       "Attr57     0.016127\n",
       "Attr59     0.016127\n",
       "Attr55     0.002304\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of missing values in each variable\n",
    "(df[missing_data_columns].isnull().sum()/len(df)*100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f770f2c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr37</th>\n",
       "      <th>Attr21</th>\n",
       "      <th>Attr27</th>\n",
       "      <th>Attr60</th>\n",
       "      <th>Attr45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24421.000000</td>\n",
       "      <td>37551.000000</td>\n",
       "      <td>4.064100e+04</td>\n",
       "      <td>4.125300e+04</td>\n",
       "      <td>41258.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>105.085363</td>\n",
       "      <td>3.884997</td>\n",
       "      <td>1.107896e+03</td>\n",
       "      <td>4.480858e+02</td>\n",
       "      <td>14.825016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3058.429830</td>\n",
       "      <td>228.668931</td>\n",
       "      <td>3.501237e+04</td>\n",
       "      <td>3.234560e+04</td>\n",
       "      <td>2428.236110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-525.520000</td>\n",
       "      <td>-1325.000000</td>\n",
       "      <td>-2.590100e+05</td>\n",
       "      <td>-1.244000e+01</td>\n",
       "      <td>-256230.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.142300</td>\n",
       "      <td>0.908225</td>\n",
       "      <td>4.504800e-02</td>\n",
       "      <td>5.545500e+00</td>\n",
       "      <td>0.019168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.096300</td>\n",
       "      <td>1.045200</td>\n",
       "      <td>1.084100e+00</td>\n",
       "      <td>9.791700e+00</td>\n",
       "      <td>0.282825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.414000</td>\n",
       "      <td>1.203700</td>\n",
       "      <td>5.139300e+00</td>\n",
       "      <td>2.018100e+01</td>\n",
       "      <td>0.955588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>398920.000000</td>\n",
       "      <td>29907.000000</td>\n",
       "      <td>4.208800e+06</td>\n",
       "      <td>4.818700e+06</td>\n",
       "      <td>366030.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Attr37        Attr21        Attr27        Attr60         Attr45\n",
       "count   24421.000000  37551.000000  4.064100e+04  4.125300e+04   41258.000000\n",
       "mean      105.085363      3.884997  1.107896e+03  4.480858e+02      14.825016\n",
       "std      3058.429830    228.668931  3.501237e+04  3.234560e+04    2428.236110\n",
       "min      -525.520000  -1325.000000 -2.590100e+05 -1.244000e+01 -256230.000000\n",
       "25%         1.142300      0.908225  4.504800e-02  5.545500e+00       0.019168\n",
       "50%         3.096300      1.045200  1.084100e+00  9.791700e+00       0.282825\n",
       "75%        11.414000      1.203700  5.139300e+00  2.018100e+01       0.955588\n",
       "max    398920.000000  29907.000000  4.208800e+06  4.818700e+06  366030.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5_missing_data_col = ['Attr37', 'Attr21', 'Attr27', 'Attr60', 'Attr45']\n",
    "df[top5_missing_data_col].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a7037e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill NA with median() of each column in dataset\n",
    "df = df.apply(lambda x: x.fillna(x.median()),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4014c0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate null values in the csv file\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c246e97c",
   "metadata": {},
   "source": [
    "##### Independent Variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951285cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the hist of data to check normality of independent variable\n",
    "df_X = df.drop(['class'],axis=1)\n",
    "df_X.hist(bins=50,figsize=(25,30))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df886837",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#heatmap - correlation matrix\n",
    "plt.figure(figsize=(55, 50)) #code reference (5-1)\n",
    "sns.heatmap(df_X.corr(), annot=True)\n",
    "plt.title('HeatMap-Correlation Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dabcdd8",
   "metadata": {},
   "source": [
    "##### Check for Multicolliniarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9467f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://www.projectpro.io/recipes/drop-out-highly-correlated-features-in-python\n",
    "# to drop features with colliniarity more than 95%\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "corr_df = pd.DataFrame(df_X.corr().abs())\n",
    "corr_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c3f9e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Multi Colliniarity analysis on Independent variables \n",
    "upper_tri = corr_df.where(np.triu(np.ones(corr_df.shape),k=1).astype(np.bool))\n",
    "print(upper_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92058221",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.9999)]\n",
    "print((to_drop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891ff18f",
   "metadata": {},
   "source": [
    "#### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71924e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'] = df['class'].replace([b'0', b'1'], [0, 1])\n",
    "\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = \"class\", data = df)\n",
    "plt.title(\"Distribution of Target Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4a1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart\n",
    "df['class'].value_counts().plot.pie(autopct = \"%.1f%%\")\n",
    "plt.title(\"Proportion of Target Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b025010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['class'],axis=1)\n",
    "ind_columns = df.drop('class',axis=1).columns\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65efcf04",
   "metadata": {},
   "source": [
    "We did normalize the attributes using StandardScaler() to scale them between 0 and 1 before running models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df0e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9410c38c",
   "metadata": {},
   "source": [
    "We chose a stratified k-fold validation algorithm. In stratified k-fold cross-validation, the original sample is randomly partitioned into k equal size subsamples in which each fold contains roughly the same proportions of class labels. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k-1 subsamples are used as training data. The cross-validation process is then repeated k times (the folds), with each of the k subsamples used exactly once as the validation data. The k results from the folds can then be averaged (or otherwise combined) to produce a single estimation. The advantage of this method is that all observations are used for both training and validation, and each observation is used for validation exactly once.\n",
    "\n",
    "The typical standard of 10 folds will be adequate for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf83ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Cross Validation Procedure\n",
    "cv = StratifiedKFold(n_splits=10, random_state=1234, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112da47b",
   "metadata": {},
   "source": [
    "#### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93363874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Metrics\n",
    "def displayModel_metrics(best_model, grid_model, features, target, cv):   \n",
    "    start = time.time()\n",
    "    cv_results = cross_validate(best_model, features, target, cv=cv, scoring=['accuracy','precision','recall','f1'], n_jobs=-1)\n",
    "    elapsed_time = (time.time() - start) \n",
    "    print ('Fold Scores:')\n",
    "    print(' ')\n",
    "    print(cv_results['test_accuracy'])\n",
    "    print(' ')\n",
    "    print('Best Accuracy   :  {:.3f}'.format(grid_model.best_score_))\n",
    "    print('Mean Accuracy   : ', cv_results['test_accuracy'].mean())\n",
    "    print('Mean Precision  : ', cv_results['test_precision'].mean())\n",
    "    print('Mean Recall     : ', cv_results['test_recall'].mean())\n",
    "    print('Mean F-Score   : ', cv_results['fscore'].mean())\n",
    "    print('Mean Fit Time   : ', cv_results['fit_time'].mean())\n",
    "    print('Mean Score Time : ', cv_results['score_time'].mean())\n",
    "    print('CV Time         : ', elapsed_time)\n",
    "    return\n",
    "\n",
    "# ROC curve plot\n",
    "def roc_curve_plot(model_fit, features, target):\n",
    "\n",
    "    sns.set_palette(\"dark\")\n",
    "\n",
    "    yhat_score = model_fit.predict_proba(features)\n",
    "\n",
    "    # Compute ROC curve for a subset of interesting classes\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in np.unique(target):\n",
    "        fpr[i], tpr[i], _ = mt.roc_curve(y, yhat_score[:, i], pos_label=i)\n",
    "        roc_auc[i] = mt.auc(fpr[i], tpr[i])\n",
    "\n",
    "    for i in np.unique(target):\n",
    "        plt.plot(fpr[i], tpr[i], label= ('class %d (area = %0.2f)' % (i, roc_auc[i])))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "\n",
    "    plt.legend(loc=\"lower right\")  \n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef96a15c",
   "metadata": {},
   "source": [
    "#### Model 1: Random Forest with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c743c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(class_weight='balanced', random_state=1234)\n",
    "rf_clf.fit(X_scaled, y)\n",
    "\n",
    "rf_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c428ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = rf_clf.predict(X_scaled)\n",
    "accuracy_score(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037b7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b379d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for Random Forest Classifier\n",
    "roc_curve_plot(rf_clf, X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40029ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_precision_recall_curve(rf_clf, X_scaled, y)\n",
    "disp.ax_.set_title('Precision-Recall Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a567714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "cv_df = pd.DataFrame(cross_validate(rf_clf, X_scaled, y, cv=cv, scoring=['accuracy','precision','recall', 'f1'], n_jobs=-1))\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5165e9",
   "metadata": {},
   "source": [
    "#### Model 2: Random Forest with GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa34ede",
   "metadata": {},
   "source": [
    "Random forest is an ensemble tree-based learning algorithm where it combines more than one algorithms of same or different kind for classifying objects. The Random Forest Classifier is a set of decision trees from randomly selected subset of training set. It aggregates the votes from different decision trees to decide the final class of the test object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f15d7c",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "\n",
    "- n_estimators: number of trees in the forest\n",
    "\n",
    "- max_depth: max number of levels in each decision tree\n",
    "\n",
    "- criterion: The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific\n",
    "\n",
    "- min_samples_split = min number of data points placed in a node before the node is split\n",
    "\n",
    "- min_samples_leaf = min number of data points allowed in a leaf node\n",
    "\n",
    "- class_weight: The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cf3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier()\n",
    "\n",
    "# define parameters       \n",
    "max_depth_RF = [5, 7, 8, 10, 12]\n",
    "random_state_RF = [1234]\n",
    "n_estimators_RF =  [100]\n",
    "criterion_RF = ['entropy']\n",
    "min_samples_leaf_RF = [3, 4, 5]\n",
    "min_samples_split_RF = [8, 10, 12]\n",
    "class_weight_RF = ['balanced']\n",
    "\n",
    "# define grid search\n",
    "# param_grid_RF = dict(n_estimators=n_estimators_RF, max_depth=max_depth_RF, random_state=random_state_RF,\n",
    "#                      criterion=criterion_RF, min_samples_leaf=min_samples_leaf_RF,\n",
    "#                     min_samples_split=min_samples_split_RF, class_weight=class_weight_RF)\n",
    "\n",
    "# search_RF = GridSearchCV(estimator=RF, param_grid=param_grid_RF, n_jobs=3, cv=cv, \n",
    "#                                scoring='accuracy',error_score=0, verbose=1)\n",
    "\n",
    "\n",
    "# define random search\n",
    "param_random_RF = dict(n_estimators=n_estimators_RF, max_depth=max_depth_RF, random_state=random_state_RF,\n",
    "                     criterion=criterion_RF, min_samples_leaf=min_samples_leaf_RF,\n",
    "                    min_samples_split=min_samples_split_RF, class_weight=class_weight_RF)\n",
    "\n",
    "\n",
    "search_RF = RandomizedSearchCV(estimator=RF, param_distributions=param_random_RF, n_jobs=3, cv=cv, \n",
    "                               scoring='accuracy',n_iter=20, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee405b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "result_RF = search_RF.fit(X_scaled, y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (result_RF.best_score_, result_RF.best_params_))\n",
    "means = result_RF.cv_results_['mean_test_score']\n",
    "stds = result_RF.cv_results_['std_test_score']\n",
    "params = result_RF.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9add293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The GridSearch algorithm determined the following optimal parameters\n",
    "best_Estimator_RF =result_RF.best_estimator_\n",
    "Coef_weights_RF = result_RF.best_estimator_.feature_importances_\n",
    "best_Estimator_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1d12b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model metrics\n",
    "displayModel_metrics(best_Estimator_RF, result_RF, X_scaled, y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d97eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = cross_val_predict(best_Estimator_RF, X_scaled, y, cv=10)\n",
    "conf_mat = confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ab6741",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eb8955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for Random Forest Classifier\n",
    "roc_curve_plot(result_RF, X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b877641",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_precision_recall_curve(best_Estimator_RF, X_scaled, y)\n",
    "disp.ax_.set_title('Precision-Recall Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c128dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "precision, recall, threshold = metrics.precision_recall_curve(y, best_Estimator_RF.predict_proba(X_scaled)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78efe0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "plt.plot(threshold, precision[:-1], label='Precision')\n",
    "plt.plot(threshold, recall[:-1], label='Recall')\n",
    "plt.xlabel('Thresold')\n",
    "plt.ylabel('Proportion')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecf707e",
   "metadata": {},
   "source": [
    "If we wanted to ensure that the model classify 95% of the financial institutions that go bankrupt  correctly we would want to select the following threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mal95_ind = np.argmin(recall >= 0.95)-1\n",
    "mal95_thresh = threshold[mal95_ind]\n",
    "mal95_precision = precision[mal95_ind]\n",
    "mal95_recall = recall[mal95_ind]\n",
    "\n",
    "print(\"Threshold:\", mal95_thresh)\n",
    "print(\"Precision:\", mal95_precision)\n",
    "print(\"Recall:\", mal95_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4605f320",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4963ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important features with their weights \n",
    "imp_feature_df = pd.DataFrame({'feature_names':ind_columns, \n",
    "                               'Coef_weights':Coef_weights_RF})\n",
    "imp_feature_df.sort_values(by='Coef_weights', inplace=True, ascending=False )\n",
    "\n",
    "imp_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6890d3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulization of important features \n",
    "%matplotlib inline\n",
    "\n",
    "ax = sns.barplot(x ='Coef_weights', y = 'feature_names',data=imp_feature_df.head(10), orient= 'h')\n",
    "ax.set_title(\"Random Forest Feature Importance\")\n",
    "ax.set_xlabel(\"Coefficient Magnitude\\n(z-score)\")\n",
    "ax.set_ylabel(\"Feature Names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1369ab67",
   "metadata": {},
   "source": [
    "#### Model 3: XGBoost with default parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b963b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf.fit(X_scaled, y)\n",
    "\n",
    "xgb_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d15d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = xgb_clf.predict(X_scaled)\n",
    "accuracy_score(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeccccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b936280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for XGB Classifier\n",
    "roc_curve_plot(xgb_clf, X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a5a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_precision_recall_curve(xgb_clf, X_scaled, y)\n",
    "disp.ax_.set_title('Precision-Recall Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1516c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "cv_df = pd.DataFrame(cross_validate(xgb_clf, X_scaled, y, cv=cv, scoring=['accuracy','precision','recall', 'f1'], n_jobs=-1))\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403ea5f4",
   "metadata": {},
   "source": [
    "#### Model 4: XGBoost with GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f1695b",
   "metadata": {},
   "source": [
    "Parameters\n",
    "\n",
    "- learning_rate: The learning rate. In each boosting step, this values shrinks the weight of new features, preventing overfitting or a local minimum. This value must be between 0 and 1. The default value is 0.3.\n",
    "\n",
    "- max_depth: The maximum depth of a tree. Be careful, greater the depth, greater the complexity of the model and more easy to overfit. This value must be an integer greater than 0 and have 6 as default.\n",
    "\n",
    "- n_estimators: The number of trees in our ensemble.\n",
    "\n",
    "- gamma: A regularization term and it’s related to the complexity of the model. It’s the minimum loss necessary to occur a - -split in a leaf. It can be any value greater than zero and has a default value of 0.\n",
    "\n",
    "- colsample_bytree: Represents the fraction of columns to be subsampled. It’s related to the speed of the algorithm and prevent overfitting. Default value is 1 but it can be any number between 0 and 1.\n",
    "\n",
    "- lambda: L2 regularization on the weights. This encourages smaller weights. Default is 1 but it can be any value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d426e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = xgb.XGBClassifier()\n",
    "\n",
    "# define parameters       \n",
    "clf_n_estimators_XGB = [200]\n",
    "# clf_learning_rate_XGB =  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5]   0.3\n",
    "# clf_max_depth_XGB = range(3, 15) 5\n",
    "# clf_colsample_bytree_XFB = [i/10.0 for i in range(1, 3)]  0.2\n",
    "# clf_gamma_XGB = [i/10.0 for i in range(1, 8)]          0.1\n",
    "# lambda_XGB = [0.1, 1.0, 5.0, 10.0, 50.0, 100.0]        0.1\n",
    "# min_child_weight = [0.1, 0.9, 0.95]                    1\n",
    "\n",
    "clf_learning_rate_XGB =  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5]\t \n",
    "clf_max_depth_XGB = range(3, 15)\t\t\t\t\t\t \n",
    "clf_colsample_bytree_XFB = [i/10.0 for i in range(1, 3)]\t\t \n",
    "clf_gamma_XGB = [0.01, 0.05, 0.1, 0.2, 0.3]\t\t\t\t \n",
    "lambda_XGB = [0.01, 0.05, 0.1, 1.0, 5.0, 10.0, 50.0, 100.0]\t\t \n",
    "min_child_weight = [0.1, 0.9, 0.95, 2, 3]\t\n",
    "random_state_XGB = [1234]\n",
    "\n",
    "# define grid search\n",
    "# param_grid_RF = dict(n_estimators=clf_n_estimators_XGB, learning_rate=clf_learning_rate_XGB, \n",
    "#                      max_depth=clf_max_depth_XGB, colsample_bytree = clf_colsample_bytree_XFB,\n",
    "#                     gamma=clf_gamma_XGB, reg_lambda=lambda_XGB)\n",
    "\n",
    "# search_RF = GridSearchCV(estimator=RF, param_grid=param_grid_RF, n_jobs=3, cv=cv, \n",
    "#                                scoring='accuracy',error_score=0, verbose=1)\n",
    "\n",
    "\n",
    "# define random search\n",
    "param_random_XGB = dict(n_estimators=clf_n_estimators_XGB, learning_rate=clf_learning_rate_XGB, \n",
    "                     max_depth=clf_max_depth_XGB, colsample_bytree = clf_colsample_bytree_XFB,\n",
    "                    gamma=clf_gamma_XGB, reg_lambda=lambda_XGB, random_state=random_state_XGB)\n",
    "\n",
    "\n",
    "search_XGB = RandomizedSearchCV(estimator=XGB, param_distributions=param_random_XGB, n_jobs=3, cv=cv, \n",
    "                               scoring='accuracy',n_iter=20, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f8cb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "result_XGB = search_XGB.fit(X_scaled, y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (result_XGB.best_score_, result_XGB.best_params_))\n",
    "means = result_XGB.cv_results_['mean_test_score']\n",
    "stds = result_XGB.cv_results_['std_test_score']\n",
    "params = result_XGB.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142803f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The GridSearch algorithm determined the following optimal parameters\n",
    "best_Estimator_XGB =result_XGB.best_estimator_\n",
    "Coef_weights_XGB = result_XGB.best_estimator_.feature_importances_\n",
    "best_Estimator_XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edc4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model metrics\n",
    "displayModel_metrics(best_Estimator_XGB, result_XGB, X_scaled, y, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f680c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve for Random Forest Classifier\n",
    "roc_curve_plot(result_XGB, X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63087bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_precision_recall_curve(best_Estimator_XGB, X_scaled, y)\n",
    "disp.ax_.set_title('Precision-Recall Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c6e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, threshold = metrics.precision_recall_curve(y, best_Estimator_XGB.predict_proba(X_scaled)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9950e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(threshold, precision[:-1], label='Precision')\n",
    "plt.plot(threshold, recall[:-1], label='Recall')\n",
    "plt.xlabel('Thresold')\n",
    "plt.ylabel('Proportion')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076e7d1d",
   "metadata": {},
   "source": [
    "If we wanted to ensure that the model classify 95% of the financial institutions that go bankrupt  correctly we would want to select the following threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c27e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mal95_ind = np.argmin(recall >= 0.95)-1\n",
    "mal95_thresh = threshold[mal95_ind]\n",
    "mal95_precision = precision[mal95_ind]\n",
    "mal95_recall = recall[mal95_ind]\n",
    "\n",
    "print(\"Threshold:\", mal95_thresh)\n",
    "print(\"Precision:\", mal95_precision)\n",
    "print(\"Recall:\", mal95_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2d12a2",
   "metadata": {},
   "source": [
    "### Feature Importance with XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e6e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important features with their weights \n",
    "imp_feature_df = pd.DataFrame({'feature_names':ind_columns, \n",
    "                               'Coef_weights':Coef_weights_XGB})\n",
    "imp_feature_df.sort_values(by='Coef_weights', inplace=True, ascending=False )\n",
    "\n",
    "imp_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24685442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulization of important features \n",
    "%matplotlib inline\n",
    "\n",
    "ax = sns.barplot(x ='Coef_weights', y = 'feature_names',data=imp_feature_df.head(10), orient= 'h')\n",
    "ax.set_title(\"XGB Feature Importance\")\n",
    "ax.set_xlabel(\"Coefficient Magnitude\\n(z-score)\")\n",
    "ax.set_ylabel(\"Feature Names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429325d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
